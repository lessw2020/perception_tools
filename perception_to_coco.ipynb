{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json/coco utils for Unity\n",
    "# lessw2020\n",
    "# https://github.com/lessw2020/perception_tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path, PurePath\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from copy import deepcopy\n",
    "import os\n",
    "from datetime import datetime as dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def require_dir(item, type=\"Dataset\"):\n",
    "    itemp = Path(item)\n",
    "    if not itemp.is_dir():\n",
    "        raise ValueError(f\"directory of type {type} not found. aborting...\")\n",
    "\n",
    "def get_sub_folders(upper_path):\n",
    "    # verify upper path\n",
    "    fpath = Path(upper_path)\n",
    "    \n",
    "    require_dir(fpath, \"Perception root dir\")  # will break with raise error if not dir\n",
    "    \n",
    "    # get required subfolders\n",
    "    # dataset\n",
    "    #subdirs = [f.path for f in os.scandir(upper_path) if f.is_dir() ]\n",
    "    \n",
    "    dataset_glob = fpath.glob(\"Dataset*\")\n",
    "    try:\n",
    "        dataset_dir = next(dataset_glob) \n",
    "    except StopIteration:\n",
    "        print(f\"** failed to get Dataset dir. aborting..\")\n",
    "        return None, None\n",
    "    \n",
    "    require_dir(dataset_dir, \"Dataset\")\n",
    "    \n",
    "    print(f\"--> using {dataset_dir.name} to generate annotations\")\n",
    "    \n",
    "    image_glob = fpath.glob(\"RGB*\")\n",
    "    \n",
    "    try:\n",
    "        image_dir = next(image_glob)\n",
    "    except StopIteration:\n",
    "        print(f\"** failed to get an image dir. aborting...\")\n",
    "        return None, None\n",
    "        \n",
    "    \n",
    "    print(f\"--> using {image_dir.name} for images\")\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "        \n",
    "    return image_dir, dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_anno_file(dataset_dir):\n",
    "    anno_file = dataset_dir/'annotation_definitions.json'\n",
    "    return anno_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_json(fpath):\n",
    "    try:\n",
    "        with open(str(fpath)) as f:\n",
    "            jh = json.load(f)\n",
    "    except:\n",
    "        raise ValueError(f\"failed to open {fpath} for read\")\n",
    "    return jh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perception_categories(anno_file, show_info=True, supercategory = \"rdt\"):\n",
    "    \n",
    "    fh = open_json(anno_file)\n",
    "    anno_list = fh['annotation_definitions']\n",
    "    spec = anno_list[0]\n",
    "    spec = spec['spec']\n",
    "    print(f\"\\n--> labels in perception definitions:\\n\")\n",
    "    for item in spec:\n",
    "        print(item)\n",
    "    \n",
    "    print(f\"\\n-->building coco categories:\")\n",
    "    coco_category_block = []\n",
    "    for item in spec:\n",
    "        holding = {}\n",
    "        holding['id']= item['label_id']\n",
    "        \n",
    "        holding['name'] = item['label_name']\n",
    "        holding['supercategory']=supercategory\n",
    "        print(holding)\n",
    "        coco_category_block.append(holding)\n",
    "    return coco_category_block\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_perception_annotations(anno_dir, image_width=1024, image_height=768):\n",
    "    \n",
    "    anno_id = 0  # can also start with 1 if desired\n",
    "    image_id = 0\n",
    "    \n",
    "    images_block = []\n",
    "    annos_block = []\n",
    "    \n",
    "    capture_files = anno_dir.glob('captures*.json')\n",
    "    \n",
    "    for j,_ in enumerate(capture_files):\n",
    "        pass\n",
    "    \n",
    "    print(f\"\\n--> {j+1} capture files detected. Processing...\")\n",
    "    \n",
    "    # processing\n",
    "    capture_files = anno_dir.glob('captures*.json')\n",
    "    \n",
    "    for item in capture_files:\n",
    "    \n",
    "        fh = open_json(item)\n",
    "        \n",
    "        captures = fh['captures']\n",
    "        \n",
    "        for image_entry in captures:\n",
    "            image_dict = {}\n",
    "            \n",
    "            image_dict['id'] = image_id\n",
    "            \n",
    "            fp = Path(image_entry['filename'])\n",
    "            \n",
    "            # it's likely you are exporting all images as same size.\n",
    "            # could open each image and check height/width, but will use passed in args for now\n",
    "            image_dict['width'] = image_width\n",
    "            image_dict['height'] = image_height\n",
    "            image_dict['file_name'] = fp.name\n",
    "            \n",
    "            # dummy values \n",
    "            image_dict['license'] = None\n",
    "            image_dict['flickr_url'] = \"\"\n",
    "            image_dict['coco_url'] = \"\"\n",
    "            image_dict['date_captured'] = \"0:00\"\n",
    "            \n",
    "            images_block.append(deepcopy(image_dict))\n",
    "            \n",
    "            annos = image_entry['annotations']\n",
    "            \n",
    "            ad = {}\n",
    "            \n",
    "            for a in annos:\n",
    "                ad.update(a)\n",
    "            \n",
    "            values = ad['values']\n",
    "                \n",
    "            coco_anno = []\n",
    "            \n",
    "            for item in values:\n",
    "                temp_anno={}\n",
    "                x = item['x']\n",
    "                y = item['y']\n",
    "                w = item['width']\n",
    "                h = item['height']\n",
    "                \n",
    "                bbox = [x,y,w,h]\n",
    "                \n",
    "                temp_anno[\"id\"] = anno_id\n",
    "                temp_anno[\"image_id\"] = image_id\n",
    "                temp_anno[\"category_id\"] = item[\"label_id\"]\n",
    "                \n",
    "                #bbox details\n",
    "                temp_anno[\"bbox\"] = bbox\n",
    "                temp_anno[\"area\"] = int(w*h)\n",
    "                \n",
    "                #segmentation - todo if needed\n",
    "                temp_anno[\"segmentation\"] = None\n",
    "                temp_anno[\"iscrowd\"] = 0\n",
    "                \n",
    "                annos_block.append(deepcopy(temp_anno))\n",
    "\n",
    "                anno_id +=1\n",
    "            \n",
    "            image_id+=1\n",
    "        \n",
    "    print(f\"--> annotation processing completed.\")\n",
    "    return images_block, annos_block\n",
    "                \n",
    "           \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_perception(base_dir, out_file=\"coco_labels.json\", image_width=1024, image_height=768):\n",
    "    \"\"\" \n",
    "    main entry for converting perception output into ready to train coco file\n",
    "    \n",
    "    note - currently image height and width are passed in /hardcoded.  Workaround is can open every image file\n",
    "    and check, or update perception to export image info...for now just using passed in vars\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    image_dir, dataset_dir = get_sub_folders(base_dir)\n",
    "    \n",
    "    mainfile = {}\n",
    "    \n",
    "    #build info section\n",
    "    infod = {}\n",
    "    \n",
    "    today = dt.today()\n",
    "    infod['year'] = str(today.year)\n",
    "    infod['date_created'] = str(today)\n",
    "\n",
    "    infod['version']= \"1.0\"\n",
    "    infod['contributor']=\"lessw2020\"\n",
    "    infod['url']='https://github.com/lessw2020/perception_tools'\n",
    "    \n",
    "    mainfile['info'] = infod\n",
    "    \n",
    "    mainfile['licenses'] = []\n",
    "    \n",
    "    # get categories\n",
    "    perception_anno = get_anno_file(dataset_dir)\n",
    "    \n",
    "    coco_cats = get_perception_categories(perception_anno)\n",
    "    \n",
    "    mainfile['categories'] = coco_cats\n",
    "    \n",
    "    #print(f\"--> mainfile = {mainfile}\")\n",
    "    \n",
    "    # get annotations\n",
    "    images_block, annos_block = get_perception_annotations(dataset_dir, \n",
    "                                                           image_width, image_height)\n",
    "    \n",
    "    mainfile['images']=images_block\n",
    "    mainfile['annotations'] = annos_block\n",
    "    \n",
    "    if out_file:\n",
    "        save_file = dataset_dir/out_file\n",
    "        with open(save_file,'w') as fh:\n",
    "            json.dump(mainfile, fh)\n",
    "    \n",
    "    # all done\n",
    "    print(f\"\\n--> Processing complete.  Total images = {len(mainfile['images'])}\\n\")\n",
    "    \n",
    "    return mainfile\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## begin processing here (ensure all cells above have been run...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perception_folder = \"/home/coffeeginu/unity_datasets/0e0ff4d0-8c5c-4dce-812f-1da379df980b/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = convert_perception(perception_folder)  # add out_name to customize, image_width and image_height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
